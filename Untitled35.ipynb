{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 0\tError: 18.248143\n",
      "Iteration 500\tError: 19.286708\n",
      "Iteration 1000\tError: 19.286708\n",
      "Iteration 1500\tError: 19.286708\n",
      "Iteration 2000\tError: 19.286708\n",
      "Iteration 2500\tError: 19.286708\n",
      "Iteration 3000\tError: 19.286708\n",
      "Iteration 3500\tError: 19.286708\n",
      "Iteration 4000\tError: 19.286708\n",
      "Iteration 4500\tError: 19.286708\n",
      "Iteration 5000\tError: 19.286708\n",
      "Iteration 5500\tError: 19.286708\n",
      "Iteration 6000\tError: 19.286708\n",
      "Iteration 6500\tError: 19.286708\n",
      "Iteration 7000\tError: 19.286708\n",
      "Iteration 7500\tError: 19.286708\n",
      "Iteration 8000\tError: 19.286708\n",
      "Iteration 8500\tError: 19.286708\n",
      "Iteration 9000\tError: 19.286708\n",
      "Iteration 9500\tError: 19.286708\n",
      "Iteration 10000\tError: 19.286708\n",
      "Iteration 10500\tError: 19.286708\n",
      "Iteration 11000\tError: 19.286708\n",
      "Iteration 11500\tError: 19.286708\n",
      "Iteration 12000\tError: 19.286708\n",
      "Iteration 12500\tError: 19.286708\n",
      "Iteration 13000\tError: 19.286708\n",
      "Iteration 13500\tError: 19.286708\n",
      "Iteration 14000\tError: 19.286708\n",
      "Iteration 14500\tError: 19.286708\n",
      "Iteration 15000\tError: 19.286708\n",
      "Iteration 15500\tError: 19.286708\n",
      "Iteration 16000\tError: 19.286708\n",
      "Iteration 16500\tError: 19.286708\n",
      "Iteration 17000\tError: 19.286708\n",
      "Iteration 17500\tError: 19.286708\n",
      "Iteration 18000\tError: 19.286708\n",
      "Iteration 18500\tError: 19.286708\n",
      "Iteration 19000\tError: 19.286708\n",
      "Iteration 19500\tError: 19.286708\n",
      "Iteration 20000\tError: 19.286708\n",
      "Iteration 20500\tError: 19.286708\n",
      "Iteration 21000\tError: 19.286708\n",
      "Iteration 21500\tError: 19.286708\n",
      "Iteration 22000\tError: 19.286708\n",
      "Iteration 22500\tError: 19.286708\n",
      "Iteration 23000\tError: 19.286708\n",
      "Iteration 23500\tError: 19.286708\n",
      "Iteration 24000\tError: 19.286708\n",
      "Iteration 24500\tError: 19.286708\n",
      "Iteration 25000\tError: 19.286708\n",
      "Iteration 25500\tError: 19.286708\n",
      "Iteration 26000\tError: 19.286708\n",
      "Iteration 26500\tError: 19.286708\n",
      "Iteration 27000\tError: 19.286708\n",
      "Iteration 27500\tError: 19.286708\n",
      "Iteration 28000\tError: 19.286708\n",
      "Iteration 28500\tError: 19.286708\n",
      "Iteration 29000\tError: 19.286708\n",
      "Iteration 29500\tError: 19.286708\n",
      "Iteration 30000\tError: 19.286708\n",
      "Iteration 30500\tError: 19.286708\n",
      "Iteration 31000\tError: 19.286708\n",
      "Iteration 31500\tError: 19.286708\n",
      "Iteration 32000\tError: 19.286708\n",
      "Iteration 32500\tError: 19.286708\n",
      "Iteration 33000\tError: 19.286708\n",
      "Iteration 33500\tError: 19.286708\n",
      "Iteration 34000\tError: 19.286708\n",
      "Iteration 34500\tError: 19.286708\n",
      "Iteration 35000\tError: 19.286708\n",
      "Iteration 35500\tError: 19.286708\n",
      "Iteration 36000\tError: 19.286708\n",
      "Iteration 36500\tError: 19.286708\n",
      "Iteration 37000\tError: 19.286708\n",
      "Iteration 37500\tError: 19.286708\n",
      "Iteration 38000\tError: 19.286708\n",
      "Iteration 38500\tError: 19.286708\n",
      "Iteration 39000\tError: 19.286708\n",
      "Iteration 39500\tError: 19.286708\n",
      "Iteration 40000\tError: 19.286708\n",
      "Iteration 40500\tError: 19.286708\n",
      "Iteration 41000\tError: 19.286708\n",
      "Iteration 41500\tError: 19.286708\n",
      "Iteration 42000\tError: 19.286708\n",
      "Iteration 42500\tError: 19.286708\n",
      "Iteration 43000\tError: 19.286708\n",
      "Iteration 43500\tError: 19.286708\n",
      "Iteration 44000\tError: 19.286708\n",
      "Iteration 44500\tError: 19.286708\n",
      "Iteration 45000\tError: 19.286708\n",
      "Iteration 45500\tError: 19.286708\n",
      "Iteration 46000\tError: 19.286708\n",
      "Iteration 46500\tError: 19.286708\n",
      "Iteration 47000\tError: 19.286708\n",
      "Iteration 47500\tError: 19.286708\n",
      "Iteration 48000\tError: 19.286708\n",
      "Iteration 48500\tError: 19.286708\n",
      "Iteration 49000\tError: 19.286708\n",
      "Iteration 49500\tError: 19.286708\n",
      "Iteration 50000\tError: 19.286708\n",
      "Input \tOutput \t\tTarget\n",
      "[ 1.    2.    1.    1.   39.25  1.    2.    2.   14.05  0.    1.  ]\t [0.38933176] \t0\n",
      "[ 1.    2.    2.    1.   41.58  2.    1.    1.   11.05  0.    2.  ]\t [0.38933176] \t0\n",
      "[ 2.    1.    2.    1.   40.96  2.    2.    1.    4.48  1.    2.  ]\t [0.38933176] \t0\n",
      "[ 1.   1.   1.   1.  47.5  1.   2.   1.   2.1  1.   2. ]\t [0.38933176] \t1\n",
      "[ 1.   2.   1.   1.  32.8  1.   2.   2.   9.5  1.   2. ]\t [0.38933176] \t0\n",
      "[ 1.    1.    2.    1.   46.81  2.    1.    2.   11.2   0.    1.  ]\t [0.38933176] \t0\n",
      "[ 1.   1.   1.   1.  53.1  1.   2.   2.   9.5  1.   2. ]\t [0.38933176] \t0\n",
      "[ 3.    2.    1.    1.   27.3   1.    2.    1.   13.96  0.    1.  ]\t [0.38933176] \t1\n",
      "[ 1.   1.   1.   1.  31.6  1.   2.   2.   2.5  1.   2. ]\t [0.38933176] \t1\n",
      "[ 2.    1.    1.    1.   53.32  2.    2.    2.   15.65  0.    1.  ]\t [0.38933176] \t0\n",
      "[ 1.    1.    2.    2.   42.85  1.    1.    3.    1.55  1.    2.  ]\t [0.38933176] \t1\n",
      "[ 2.    1.    2.    2.   59.8   1.    2.    2.   14.43  0.    1.  ]\t [0.38933176] \t0\n",
      "[ 1.    1.    1.    1.   40.11  2.    2.    1.    8.6   1.    2.  ]\t [0.38933176] \t0\n",
      "[ 1.    2.    1.    1.   34.85  1.    2.    2.   13.05  0.    1.  ]\t [0.38933176] \t0\n",
      "[ 2.    1.    1.    2.   53.93  2.    2.    3.   12.74  0.    1.  ]\t [0.38933176] \t0\n",
      "[ 1.    2.    1.    1.   38.65  2.    2.    2.   11.05  0.    2.  ]\t [0.38933176] \t0\n",
      "[ 1.    1.    1.    1.   32.1   1.    2.    3.   10.05  1.    2.  ]\t [0.38933176] \t0\n",
      "[ 2.    2.    1.    1.   35.95  2.    2.    3.   11.96  0.    2.  ]\t [0.38933176] \t0\n",
      "[ 1.    2.    1.    1.   43.75  1.    2.    3.    9.45  1.    2.  ]\t [0.38933176] \t0\n",
      "[ 1.    2.    1.    1.   43.5   1.    2.    3.    9.95  1.    2.  ]\t [0.38933176] \t0\n",
      "[ 2.    1.    1.    1.   31.    1.    2.    2.   12.35  0.    1.  ]\t [0.38933176] \t0\n",
      "[ 1.   2.   1.   1.  44.1  1.   2.   3.  12.1  0.   1. ]\t [0.38933176] \t0\n",
      "[ 1.    1.    1.    1.   32.    1.    2.    3.   11.45  0.    1.  ]\t [0.38933176] \t0\n",
      "[ 1.   1.   1.   1.  34.5  1.   2.   1.  10.6  0.   2. ]\t [0.38933176] \t0\n",
      "[ 1.    1.    1.    1.   37.65  1.    2.    2.    8.55  1.    2.  ]\t [0.38933176] \t0\n",
      "[ 3.   2.   1.   1.  40.9  2.   2.   1.   3.5  1.   2. ]\t [0.38933176] \t1\n",
      "[ 1.   2.   1.   1.  37.5  1.   2.   1.   9.   1.   2. ]\t [0.38933176] \t0\n",
      "[ 2.    1.    1.    2.   33.05  1.    2.    3.    5.13  1.    2.  ]\t [0.38933176] \t1\n",
      "[ 1.   2.   2.   1.  29.   1.   2.   2.   7.9  1.   2. ]\t [0.38933176] \t0\n",
      "[ 3.    2.    1.    1.   41.63  2.    2.    3.   15.38  0.    1.  ]\t [0.38933176] \t0\n",
      "[ 3.    2.    1.    1.   37.5   2.    2.    1.   14.75  0.    1.  ]\t [0.38933176] \t0\n",
      "[ 2.    1.    1.    1.   31.35  2.    2.    1.    9.57  1.    2.  ]\t [0.38933176] \t0\n",
      "[ 2.    1.    1.    1.   34.22  2.    2.    2.   11.3   0.    2.  ]\t [0.38933176] \t0\n",
      "[ 2.    1.    1.    1.   39.55  1.    2.    2.   15.    0.    1.  ]\t [0.38933176] \t0\n",
      "[ 3.    2.    1.    2.   28.55  2.    2.    2.    2.83  1.    2.  ]\t [0.38933176] \t1\n",
      "[ 2.    2.    1.    1.   38.71  2.    2.    1.   13.52  0.    1.  ]\t [0.38933176] \t0\n",
      "[ 1.    2.    1.    1.   47.49  2.    2.    3.   12.8   0.    1.  ]\t [0.38933176] \t0\n",
      "[ 1.    2.    2.    1.   39.6   1.    2.    3.   13.05  0.    1.  ]\t [0.38933176] \t0\n",
      "[ 2.    1.    1.    1.   29.85  1.    2.    3.   12.09  0.    2.  ]\t [0.38933176] \t0\n",
      "[ 2.    2.    1.    1.   21.3   1.    2.    1.   12.35  0.    2.  ]\t [0.38933176] \t0\n",
      "[ 1.    2.    1.    1.   60.55  1.    2.    3.   13.3   0.    1.  ]\t [0.38933176] \t0\n",
      "[ 2.    2.    1.    1.   28.05  1.    1.    1.   12.13  0.    2.  ]\t [0.38933176] \t0\n",
      "[ 1.    1.    2.    1.   35.85  1.    1.    1.   11.8   0.    1.  ]\t [0.38933176] \t0\n",
      "[ 2.    2.    1.    1.   41.72  2.    2.    2.    2.68  1.    2.  ]\t [0.38933176] \t1\n",
      "[ 3.    2.    1.    1.   29.58  1.    2.    1.   12.2   0.    1.  ]\t [0.38933176] \t1\n",
      "[ 3.    2.    1.    1.   38.02  2.    2.    2.    4.1   1.    2.  ]\t [0.38933176] \t1\n",
      "[ 1.    1.    2.    2.   37.58  1.    1.    3.    2.    1.    2.  ]\t [0.38933176] \t1\n",
      "[ 2.    2.    1.    2.   29.6   2.    2.    2.    2.72  1.    2.  ]\t [0.38933176] \t1\n",
      "[ 1.    1.    1.    1.   30.71  1.    2.    2.    4.87  1.    2.  ]\t [0.38933176] \t1\n",
      "[ 2.    1.    2.    2.   38.03  1.    1.    3.    1.98  1.    2.  ]\t [0.38933176] \t1\n",
      "[ 2.    1.    1.    2.   31.31  1.    2.    3.    4.24  1.    2.  ]\t [0.38933176] \t1\n",
      "[ 3.    2.    1.    2.   28.58  2.    2.    2.    2.83  1.    2.  ]\t [0.38933176] \t1\n",
      "[ 3.    2.    1.    1.   41.69  2.    2.    1.    3.33  1.    2.  ]\t [0.38933176] \t1\n",
      "[ 3.    2.    1.    2.   29.22  2.    2.    2.    3.17  1.    2.  ]\t [0.38933176] \t1\n",
      "[ 3.    2.    1.    2.   29.21  2.    2.    2.    3.17  1.    2.  ]\t [0.38933176] \t1\n",
      "[ 2.    1.    2.    2.   41.89  1.    1.    2.    2.51  1.    2.  ]\t [0.38933176] \t1\n",
      "[ 1.    1.    1.    1.   44.05  1.    2.    1.    2.19  1.    2.  ]\t [0.38933176] \t1\n",
      "[ 3.    2.    1.    2.   28.68  2.    2.    2.    2.83  1.    2.  ]\t [0.38933176] \t1\n",
      "[ 3.    2.    1.    2.   32.44  2.    2.    2.    3.04  1.    2.  ]\t [0.38933176] \t1\n",
      "[ 1.    1.    1.    1.   43.39  1.    2.    1.    2.2   1.    2.  ]\t [0.38933176] \t1\n",
      "[ 2.    1.    1.    2.   31.95  1.    2.    3.    6.81  1.    2.  ]\t [0.38933176] \t1\n",
      "[ 3.    2.    1.    1.   36.53  2.    2.    1.    3.26  1.    2.  ]\t [0.38933176] \t1\n",
      "[ 2.    1.    1.    1.   38.63  1.    2.    1.    2.44  1.    2.  ]\t [0.38933176] \t1\n",
      "[ 3.    2.    1.    1.   27.64  1.    2.    1.   10.91  0.    1.  ]\t [0.38933176] \t1\n",
      "[ 2.    1.    1.    2.   32.14  1.    2.    3.    4.67  1.    2.  ]\t [0.38933176] \t1\n",
      "[ 3.    2.    1.    2.   31.21  2.    2.    2.    2.59  1.    2.  ]\t [0.38933176] \t1\n",
      "[ 2.    1.    1.    2.   32.82  1.    2.    3.    5.01  1.    2.  ]\t [0.38933176] \t1\n",
      "[ 2.    1.    1.    2.   35.61  1.    2.    3.    4.59  1.    2.  ]\t [0.38933176] \t1\n",
      "[ 1.    1.    1.    1.   45.25  1.    2.    2.    1.83  1.    2.  ]\t [0.38933176] \t1\n",
      "[ 1.    1.    1.    1.   33.66  1.    2.    2.    2.72  1.    2.  ]\t [0.38933176] \t1\n",
      "[ 2.    2.    1.    2.   33.35  2.    2.    2.    2.65  1.    2.  ]\t [0.38933176] \t1\n",
      "[ 2.    1.    1.    2.   31.11  1.    2.    3.    4.14  1.    2.  ]\t [0.38933176] \t1\n",
      "[ 3.    2.    1.    1.   41.12  2.    2.    1.    3.28  1.    2.  ]\t [0.38933176] \t1\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "# Transfer function\n",
    "def sigmoid(x, Derivative=False):\n",
    "    if not Derivative:\n",
    "        return 1 / (1 + np.exp (-x))\n",
    "    else:\n",
    "        out = sigmoid(x)\n",
    "        return out * (1 - out)\n",
    "    \n",
    "def linear(x, Derivative=False):\n",
    "    if not Derivative:\n",
    "        return x\n",
    "    else:\n",
    "        return np.ones(x.shape)\n",
    "    \n",
    "def gaussian(x, Derivative=False):\n",
    "    if not Derivative:\n",
    "        return np.exp(-x**2)\n",
    "    else:\n",
    "        return -2 * x * np.exp(-x**2)\n",
    "    \n",
    "def tanh(x, Derivative=False):\n",
    "    if not Derivative:\n",
    "        return np.tanh(x)\n",
    "    else:\n",
    "        return 1.0 - np.tanh(x)**2\n",
    "\t\t\n",
    "class backPropNN:\n",
    "    \"\"\"Class defining a NN using Back Propagation\"\"\"\n",
    "    \n",
    "    # Class Members (internal variables that are accessed with backPropNN.member)\n",
    "    \n",
    "    numLayers = 0\n",
    "    shape = None\n",
    "    weights = []\n",
    "    \n",
    "    # Class Methods (internal functions that can be called)\n",
    "    \n",
    "    def __init__(self, numNodes, transferFunctions=None):\n",
    "        \"\"\"Initialise the NN - setup the layers and initial weights\"\"\"\n",
    "\n",
    "        # Layer info\n",
    "        self.numLayers = len(numNodes) - 1\n",
    "        self.shape = numNodes\n",
    "        \n",
    "        if transferFunctions is None:\n",
    "            layerTFs = []\n",
    "            for i in range(self.numLayers):\n",
    "                if i == self.numLayers - 1:\n",
    "                    layerTFs.append(linear)\n",
    "                else:\n",
    "                    layerTFs.append(sigmoid)\n",
    "        else:\n",
    "            if len(numNodes) != len(transferFunctions):\n",
    "                raise ValueError(\"Number of transfer functions must match the number of layers: minus input layer\")\n",
    "            elif transferFunctions[0] is not None:\n",
    "                raise ValueError(\"The Input layer doesn't need a a transfer function: give it [None,...]\")\n",
    "            else:\n",
    "                layerTFs = transferFunctions[1:]\n",
    "\n",
    "        self.tFunctions = layerTFs        \n",
    "        \n",
    "        \n",
    "        # Input/Output data from last run\n",
    "        self._layerInput = []\n",
    "        self._layerOutput = []\n",
    "        self._previousWeightDelta = []     \n",
    "       \n",
    "        # Create the weight arrays\n",
    "        for (l1,l2) in zip(numNodes[:-1],numNodes[1:]):\n",
    "            self.weights.append(np.random.normal(scale=0.1,size=(l2,l1+1)))       \n",
    "            self._previousWeightDelta.append(np.zeros((l2,l1+1)))\n",
    "        \n",
    "        \n",
    "    # Forward Pass method\n",
    "    \"\"\"Get the input data and run it through the NN\"\"\"\n",
    "    def FP(self, input):\n",
    "\n",
    "        delta = []\n",
    "        numExamples = input.shape[0]\n",
    "\n",
    "        # Clean away the values from the previous layer\n",
    "        self._layerInput = []\n",
    "        self._layerOutput = []\n",
    "        \n",
    "        for index in range(self.numLayers):\n",
    "            #Get input to the layer\n",
    "            if index ==0:\n",
    "                layerInput = self.weights[0].dot(np.vstack([input.T, np.ones([1, numExamples])]))\n",
    "            else:\n",
    "                layerInput = self.weights[index].dot(np.vstack([self._layerOutput[-1],np.ones([1,numExamples])]))\n",
    "\n",
    "            self._layerInput.append(layerInput)\n",
    "            self._layerOutput.append(self.tFunctions[index](layerInput))\n",
    "            \n",
    "        return self._layerOutput[-1].T\n",
    "            \n",
    "    # backPropagation method\n",
    "    def backProp(self, input, target, learningRate = 0.3, momentum=0.9):\n",
    "        \"\"\"Get the error, deltas and back propagate to update the weights\"\"\"\n",
    "\n",
    "        delta = []\n",
    "        numExamples = input.shape[0]\n",
    "        \n",
    "        # First run the network\n",
    "        self.FP(input)\n",
    "                 \n",
    "        # Calculate the deltas for each node\n",
    "        for index in reversed(range(self.numLayers)):\n",
    "            if index == self.numLayers - 1:\n",
    "                # If the output layer, then compare to the target values\n",
    "                output_delta = self._layerOutput[index] - target.T\n",
    "                error = np.sum(output_delta**2)\n",
    "                delta.append(output_delta * self.tFunctions[index](self._layerInput[index], True))\n",
    "            else:\n",
    "                # If a hidden layer. compare to the following layer's delta\n",
    "                delta_pullback = self.weights[index + 1].T.dot(delta[-1])\n",
    "                delta.append(delta_pullback[:-1,:] * self.tFunctions[index](self._layerInput[index], True))\n",
    "                \n",
    "        # Compute updates to each weight\n",
    "        for index in range(self.numLayers):\n",
    "            delta_index = self.numLayers - 1 - index\n",
    "            \n",
    "            if index == 0:\n",
    "                layerOutput = np.vstack([input.T, np.ones([1, numExamples])])\n",
    "            else:\n",
    "                layerOutput = np.vstack([self._layerOutput[index - 1], np.ones([1,self._layerOutput[index -1].shape[1]])])\n",
    "\n",
    "            thisWeightDelta = np.sum(\\\n",
    "                    layerOutput[None,:,:].transpose(2,0,1) * delta[delta_index][None,:,:].transpose(2,1,0) \\\n",
    "                    , axis = 0)\n",
    "            \n",
    "            weightDelta = learningRate * thisWeightDelta + momentum * self._previousWeightDelta[index]\n",
    "            \n",
    "            self.weights[index] -= weightDelta\n",
    "            \n",
    "            self._previousWeightDelta[index] = weightDelta\n",
    "            \n",
    "        return error\n",
    "\t\t\n",
    "import pandas as pd\n",
    "path = pd.read_csv('Data_Balanceada3.csv')\n",
    "Input = path.iloc[:,0:11].values\n",
    "Target = path.iloc[:,-1].values\n",
    "transferFunctions = [None, sigmoid, sigmoid]\n",
    "    \n",
    "NN = backPropNN((11,5,1), transferFunctions)\n",
    "\n",
    "maxIterations = 50000\n",
    "minError = 1e-5\n",
    "\n",
    "for i in range(maxIterations + 1):\n",
    "    Error = NN.backProp(Input, Target, learningRate=0.3, momentum=0.9)\n",
    "    if i % 500 == 0:\n",
    "        print(\"Iteration {0}\\tError: {1:0.6f}\".format(i,Error))\n",
    "    if Error <= minError:\n",
    "        print(\"Minimum error reached at iteration {0}\".format(i))\n",
    "        break\n",
    "\n",
    "Output = NN.FP(Input)\n",
    "\n",
    "print( 'Input \\tOutput \\t\\tTarget')\n",
    "for i in range(Input.shape[0]):\n",
    "    print ('{0}\\t {1} \\t{2}'.format(Input[i], Output[i], Target[i]))\n",
    "\n",
    "\n",
    " \n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
